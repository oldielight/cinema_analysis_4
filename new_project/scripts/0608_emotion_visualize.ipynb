{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-c1de5e2c44a34fe48631a47fe8e3dc33.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-c1de5e2c44a34fe48631a47fe8e3dc33.vega-embed details,\n",
       "  #altair-viz-c1de5e2c44a34fe48631a47fe8e3dc33.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-c1de5e2c44a34fe48631a47fe8e3dc33\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-c1de5e2c44a34fe48631a47fe8e3dc33\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-c1de5e2c44a34fe48631a47fe8e3dc33\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-6b714d71b27149e712955ce587b401c1\"}, \"mark\": {\"type\": \"circle\", \"opacity\": 0.8, \"size\": 70}, \"encoding\": {\"color\": {\"field\": \"valence\", \"scale\": {\"scheme\": \"turbo\"}, \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"id\", \"type\": \"quantitative\"}, {\"field\": \"text\", \"type\": \"nominal\"}, {\"field\": \"emotions\", \"type\": \"nominal\"}, {\"field\": \"valence\", \"type\": \"quantitative\"}, {\"field\": \"situation\", \"type\": \"nominal\"}, {\"field\": \"situation_type\", \"type\": \"nominal\"}], \"x\": {\"field\": \"start\", \"title\": \"Time (s)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"valence\", \"scale\": {\"domain\": [0, 1]}, \"title\": \"Emotion Valence (0\\u20131)\", \"type\": \"quantitative\"}}, \"height\": 350, \"params\": [{\"name\": \"param_1\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"title\": \"Cure (1997) Subtitle-based Emotion Valence Timeline\", \"width\": 850, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-6b714d71b27149e712955ce587b401c1\": [{\"id\": 20, \"start\": 178.596, \"end\": 180.598, \"text\": \"- You are?\\n- Takabe, from headquarters.\", \"emotions\": \"['neutral']\", \"situation\": \"introducing oneself\", \"situation_type\": \"dialogue\", \"valence\": 0.5}, {\"id\": 21, \"start\": 180.723, \"end\": 182.766, \"text\": \"Thank you for coming.\", \"emotions\": \"['happiness']\", \"situation\": \"expressing gratitude\", \"situation_type\": \"social interaction\", \"valence\": 1.0}, {\"id\": 22, \"start\": 182.933, \"end\": 186.312, \"text\": \"Mr. Takabe,\\ndo you want to see the cleaner...\", \"emotions\": \"['neutral']\", \"situation\": \"meeting a cleaner\", \"situation_type\": \"introduction\", \"valence\": 0.5}, {\"id\": 23, \"start\": 186.437, \"end\": 188.772, \"text\": \"- who found the body?\\n- No.\", \"emotions\": \"['neutral', 'contempt']\", \"situation\": \"investigating a murder\", \"situation_type\": \"crime\", \"valence\": 0.475}, {\"id\": 24, \"start\": 189.982, \"end\": 194.236, \"text\": \"A prostitute. Something like this\\nwas bound to happen someday.\", \"emotions\": \"['sadness', 'contempt']\", \"situation\": \"condemning someone's actions\", \"situation_type\": \"judgment\", \"valence\": 0.375}, {\"id\": 25, \"start\": 195.529, \"end\": 198.866, \"text\": \"- I'm Takabe.\\n- Yasukawa, from the precinct.\", \"emotions\": \"['neutral']\", \"situation\": \"introducing oneself\", \"situation_type\": \"social\", \"valence\": 0.5}, {\"id\": 26, \"start\": 199.533, \"end\": 200.951, \"text\": \"Find anything?\", \"emotions\": \"['neutral']\", \"situation\": \"searching for something\", \"situation_type\": \"investigation\", \"valence\": 0.5}, {\"id\": 27, \"start\": 201.243, \"end\": 202.453, \"text\": \"Yes.\", \"emotions\": \"['neutral']\", \"situation\": \"simple agreement\", \"situation_type\": \"dialogue\", \"valence\": 0.5}, {\"id\": 28, \"start\": 239.823, \"end\": 245.329, \"text\": \"If it was this Kuwano guy,\\nhe took off in the raw.\", \"emotions\": \"['neutral']\", \"situation\": \"investigating a suspect\", \"situation_type\": \"investigation\", \"valence\": 0.5}, {\"id\": 29, \"start\": 245.996, \"end\": 250.167, \"text\": \"And he left us his ID.\", \"emotions\": \"['surprise', 'neutral']\", \"situation\": \"inheriting an id\", \"situation_type\": \"family\", \"valence\": 0.6}, {\"id\": 30, \"start\": 253.587, \"end\": 254.964, \"text\": \"Excuse me.\", \"emotions\": \"['neutral']\", \"situation\": \"polite conversation\", \"situation_type\": \"social\", \"valence\": 0.5}, {\"id\": 31, \"start\": 263.347, \"end\": 268.435, \"text\": \"She was struck with a blunt object,\\nbut she died from loss of blood.\", \"emotions\": \"['sadness', 'neutral']\", \"situation\": \"murder investigation\", \"situation_type\": \"crime\", \"valence\": 0.4}, {\"id\": 32, \"start\": 269.186, \"end\": 271.814, \"text\": \"It wouldn't have taken long.\", \"emotions\": \"['sadness', 'neutral']\", \"situation\": \"reflection on past event\", \"situation_type\": \"introspection\", \"valence\": 0.4}, {\"id\": 33, \"start\": 272.439, \"end\": 276.819, \"text\": \"Both carotid arteries\\nhave been neatly severed.\", \"emotions\": \"['disgust', 'sadness']\", \"situation\": \"victim of brutal murder\", \"situation_type\": \"crime\", \"valence\": 0.35}, {\"id\": 34, \"start\": 277.778, \"end\": 281.532, \"text\": \"Have you ever seen wounds\\nlike this before?\", \"emotions\": \"['disgust', 'surprise']\", \"situation\": \"examining wounds\", \"situation_type\": \"medical\", \"valence\": 0.55}, {\"id\": 35, \"start\": 281.657, \"end\": 282.783, \"text\": \"No.\", \"emotions\": \"['contempt']\", \"situation\": \"refusing something\", \"situation_type\": \"conflict\", \"valence\": 0.45}, {\"id\": 36, \"start\": 283.534, \"end\": 284.535, \"text\": \"I see.\", \"emotions\": \"['neutral']\", \"situation\": \"realization\", \"situation_type\": \"introspection\", \"valence\": 0.5}, {\"id\": 37, \"start\": 285.452, \"end\": 289.206, \"text\": \"But the perp is no ordinary character.\", \"emotions\": \"['neutral']\", \"situation\": \"describing a suspect\", \"situation_type\": \"investigation\", \"valence\": 0.5}, {\"id\": 38, \"start\": 290.374, \"end\": 294.837, \"text\": \"You don't have to go this far\\njust to kill someone.\", \"emotions\": \"['anger', 'contempt']\", \"situation\": \"confronting a killer\", \"situation_type\": \"confrontation\", \"valence\": 0.35}, {\"id\": 39, \"start\": 297.464, \"end\": 301.385, \"text\": \"The suspect may have\\na motorcycle or a bicycle.\", \"emotions\": \"['neutral']\", \"situation\": \"describing a suspect\", \"situation_type\": \"investigation\", \"valence\": 0.5}, {\"id\": 40, \"start\": 302.136, \"end\": 306.015, \"text\": \"Check all the service roads.\\nI'm on my way.\", \"emotions\": \"['neutral']\", \"situation\": \"giving directions\", \"situation_type\": \"instruction\", \"valence\": 0.5}, {\"id\": 41, \"start\": 317.067, \"end\": 319.778, \"text\": \"I'm going to check out his neighborhood.\\nYou want to come?\", \"emotions\": \"['neutral']\", \"situation\": \"inviting to a trip\", \"situation_type\": \"social\", \"valence\": 0.5}, {\"id\": 42, \"start\": 337.421, \"end\": 339.631, \"text\": \"Takabe, here.\", \"emotions\": \"['neutral']\", \"situation\": \"calling someone\", \"situation_type\": \"dialogue\", \"valence\": 0.5}, {\"id\": 43, \"start\": 346.055, \"end\": 349.224, \"text\": \"<i>Then there was blood everywhere.</i>\", \"emotions\": \"[]\", \"situation\": \"unknown\", \"situation_type\": \"unknown\", \"valence\": 0.5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# 분석 결과 파일 경로\n",
    "csv_path = \"../data/processed/cure_llm_labeled_sample.csv\"\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# valence 시각화\n",
    "chart = alt.Chart(df).mark_circle(size=70, opacity=0.8).encode(\n",
    "    x=alt.X('start', title='Time (s)'),\n",
    "    y=alt.Y('valence', title='Emotion Valence (0–1)', scale=alt.Scale(domain=[0, 1])),\n",
    "    color=alt.Color('valence:Q', scale=alt.Scale(scheme='turbo')),\n",
    "    tooltip=['id', 'text', 'emotions', 'valence', 'situation', 'situation_type']\n",
    ").properties(\n",
    "    width=850,\n",
    "    height=350,\n",
    "    title=\"Cure (1997) Subtitle-based Emotion Valence Timeline\"\n",
    ")\n",
    "\n",
    "chart.interactive().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p5_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
